*** Begin Patch
*** Add File: scripts/analyze_modules_columns.py
+#!/usr/bin/env python3
+"""
+Analyse SQL-focused pour extraire tables -> colonnes attendues.
+Règle : n'extraire que des identifiants valides (^[A-Za-z_][A-Za-z0-9_]*$).
+Génère reports/SQL_SCHEMA_HINTS.md et db/schema_hints.yaml (format simple).
+Usage:
+    python scripts/analyze_modules_columns.py
+"""
+import os
+import re
+from collections import defaultdict
+
+ROOT = os.path.dirname(os.path.dirname(__file__))
+SEARCH_PATHS = ["modules", "ui", "lib", "scripts"]
+OUT_DIR = os.path.join(ROOT, "reports")
+DB_DIR = os.path.join(ROOT, "db")
+MD_FILE = os.path.join(OUT_DIR, "SQL_SCHEMA_HINTS.md")
+HINTS_FILE = os.path.join(DB_DIR, "schema_hints.yaml")
+
+# Patterns stricts
+INSERT_RE = re.compile(r"INSERT\s+INTO\s+([A-Za-z0-9_]+)\s*\(([^)]+)\)", re.IGNORECASE)
+UPDATE_SET_RE = re.compile(r"UPDATE\s+([A-Za-z0-9_]+)\s+SET\s+([^;]+)", re.IGNORECASE | re.S)
+SELECT_FROM_RE = re.compile(r"SELECT\s+(.*?)\s+FROM\s+([A-Za-z0-9_]+)", re.IGNORECASE | re.S)
+ASSIGN_COL_RE = re.compile(r"([A-Za-z_][A-Za-z0-9_]*)\s*=")
+IDENT_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]*$")
+
+def find_python_files():
+    for p in SEARCH_PATHS:
+        base = os.path.join(ROOT, p)
+        if not os.path.isdir(base):
+            continue
+        for root, _, files in os.walk(base):
+            for f in files:
+                if f.endswith(".py"):
+                    yield os.path.join(root, f)
+
+def extract_from_text(text):
+    """Return dict table->set(cols) found in text (only valid identifiers)."""
+    result = defaultdict(set)
+    # INSERT (...) patterns
+    for m in INSERT_RE.finditer(text):
+        table = m.group(1)
+        cols = [c.strip().strip('`"') for c in m.group(2).split(",")]
+        for c in cols:
+            if IDENT_RE.match(c):
+                result[table].add(c)
+    # UPDATE ... SET a=..., b=...
+    for m in UPDATE_SET_RE.finditer(text):
+        table = m.group(1)
+        set_clause = m.group(2)
+        for c in ASSIGN_COL_RE.findall(set_clause):
+            if IDENT_RE.match(c):
+                result[table].add(c)
+    # SELECT columns FROM table
+    for m in SELECT_FROM_RE.finditer(text):
+        cols_part = m.group(1)
+        table = m.group(2)
+        parts = re.split(r",(?![^(]*\))", cols_part)
+        for p in parts:
+            p = p.strip()
+            if "." in p:
+                p = p.split(".")[-1]
+            p = re.sub(r"\s+AS\s+.*$", "", p, flags=re.IGNORECASE)
+            token = re.match(r"([A-Za-z_][A-Za-z0-9_]*)", p)
+            if token:
+                name = token.group(1)
+                if IDENT_RE.match(name):
+                    result[table].add(name)
+    return result
+
+def extract_hints_from_file(path):
+    try:
+        text = open(path, "r", encoding="utf-8", errors="ignore").read()
+    except Exception:
+        return defaultdict(set)
+    return extract_from_text(text)
+
+def main():
+    os.makedirs(OUT_DIR, exist_ok=True)
+    os.makedirs(DB_DIR, exist_ok=True)
+    table_map = defaultdict(set)
+    scanned = 0
+    for path in find_python_files():
+        scanned += 1
+        res = extract_hints_from_file(path)
+        for t, cols in res.items():
+            table_map[t].update(cols)
+    # write human report
+    with open(MD_FILE, "w", encoding="utf-8") as fh:
+        fh.write("# SQL Schema Hints\n\n")
+        fh.write(f"Files scanned: {scanned}\n\n")
+        for t in sorted(table_map.keys()):
+            fh.write(f"### Table: `{t}`\n\n")
+            if table_map[t]:
+                fh.write("- Columns detected:\n")
+                for c in sorted(table_map[t]):
+                    fh.write(f"  - `{c}`\n")
+            else:
+                fh.write("- Columns detected: *none*\n")
+            fh.write("\n")
+    # write simple YAML-like manifest (no dependency)
+    with open(HINTS_FILE, "w", encoding="utf-8") as jf:
+        jf.write("# schema_hints.yaml (generated)\n")
+        jf.write("# You can edit this file to correct or add expected_columns before running the updater.\n\n")
+        for t in sorted(table_map.keys()):
+            jf.write(f"{t}:\n")
+            jf.write("  expected_columns:\n")
+            for c in sorted(table_map[t]):
+                jf.write(f"    - {c}\n")
+    print("Generated:", MD_FILE, "and", HINTS_FILE)
+
+if __name__ == "__main__":
+    main()
+
*** End Patch
*** Begin Patch
*** Add File: scripts/update_db_structure.py
+#!/usr/bin/env python3
+"""
+Safe updater:
+- load db/schema_hints.yaml (simple parser) or run analyzer
+- validate expected column names and skip invalids (report them)
+- for missing expected column:
+    - if close/case-insensitive match exists -> candidate
+      * try ALTER TABLE RENAME COLUMN
+      * else ADD new column and COPY data
+    - else ADD new column with guessed type
+- create timestamped backup before changes
+- execute in transaction; rollback & restore on failure
+- write UTF-8 reports: migration_report_<ts>.md and migration_report_failed_<ts>.md
+- avoid non-ASCII in stdout; force UTF-8 for stdout/stderr when possible
+"""
+import os
+import sys
+import sqlite3
+import shutil
+import datetime
+import traceback
+from collections import defaultdict
+from difflib import get_close_matches
+import re
+
+# try to set stdout/stderr to utf-8 where possible
+try:
+    sys.stdout.reconfigure(encoding="utf-8")
+    sys.stderr.reconfigure(encoding="utf-8")
+except Exception:
+    pass
+
+ROOT = os.path.dirname(os.path.dirname(__file__))
+DB_PATH = os.path.join(ROOT, "association.db")
+HINTS_FILE = os.path.join(ROOT, "db", "schema_hints.yaml")
+REPORTS_DIR = os.path.join(ROOT, "reports")
+ANALYZE_SCRIPT = os.path.join(ROOT, "scripts", "analyze_modules_columns.py")
+os.makedirs(REPORTS_DIR, exist_ok=True)
+
+IDENT_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]*$")
+
+def now_ts():
+    return datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
+
+def safe_print(*args, **kwargs):
+    try:
+        print(*args, **kwargs)
+        sys.stdout.flush()
+    except Exception:
+        pass
+
+def safe_open(path, mode="r"):
+    return open(path, mode, encoding="utf-8")
+
+def load_hints():
+    if os.path.exists(HINTS_FILE):
+        with safe_open(HINTS_FILE) as f:
+            content = f.read()
+    else:
+        if os.path.exists(ANALYZE_SCRIPT):
+            safe_print("Running analyzer to generate hints...")
+            os.system(f'{sys.executable} "{ANALYZE_SCRIPT}"')
+            if os.path.exists(HINTS_FILE):
+                with safe_open(HINTS_FILE) as f:
+                    content = f.read()
+            else:
+                return {}
+        else:
+            return {}
+    hints = {}
+    cur = None
+    for line in content.splitlines():
+        if not line.strip() or line.strip().startswith("#"):
+            continue
+        if not line.startswith(" "):
+            cur = line.split(":", 1)[0].strip()
+            hints[cur] = {"expected_columns": []}
+        else:
+            s = line.strip()
+            if s.startswith("- "):
+                hints[cur]["expected_columns"].append(s[2:].strip())
+    return hints
+
+def get_db_schema(conn):
+    cur = conn.cursor()
+    cur.execute("SELECT name FROM sqlite_master WHERE type='table'")
+    tables = [r[0] for r in cur.fetchall()]
+    schema = {}
+    for t in tables:
+        cur.execute(f"PRAGMA table_info('{t}')")
+        schema[t] = [r[1] for r in cur.fetchall()]
+    return schema
+
+def backup_db(path):
+    bak = f"{path}.{now_ts()}.bak"
+    shutil.copy2(path, bak)
+    return bak
+
+def guess_type(col):
+    n = col.lower()
+    if any(k in n for k in ("date","day","time")):
+        return "TEXT DEFAULT ''"
+    if any(k in n for k in ("prix","price","cost","montant","valeur")):
+        return "REAL DEFAULT 0.0"
+    if any(k in n for k in ("qty","quant","count","stock","solde","amount","quantite","ecart")):
+        return "INTEGER DEFAULT 0"
+    if n in ("id","event_id","article_id"):
+        return "INTEGER DEFAULT 0"
+    return "TEXT DEFAULT ''"
+
+def write_report(fname, env, ops, tb_text=None, success=True, skipped=None):
+    path = os.path.join(REPORTS_DIR, f"{fname}_{now_ts()}.md")
+    try:
+        with open(path, "w", encoding="utf-8") as fh:
+            fh.write("# Migration Report\n\n")
+            fh.write(f"- timestamp: {datetime.datetime.now().isoformat()}\n")
+            fh.write(f"- success: {success}\n\n")
+            fh.write("## Environment\n\n")
+            for k,v in env.items():
+                fh.write(f"- {k}: {v}\n")
+            fh.write("\n## Operations\n\n")
+            for o in ops:
+                fh.write(f"- {o}\n")
+            if skipped:
+                fh.write("\n## Skipped invalid column names\n\n")
+                for s in skipped:
+                    fh.write(f"- {s}\n")
+            if tb_text:
+                fh.write("\n## Traceback\n\n```\n")
+                fh.write(tb_text)
+                fh.write("\n```\n")
+        return path
+    except Exception as e:
+        safe_print("Failed to write report:", e)
+        return None
+
+def attempt_rename(conn, table, old, new):
+    cur = conn.cursor()
+    try:
+        sql = f'ALTER TABLE "{table}" RENAME COLUMN "{old}" TO "{new}"'
+        cur.execute(sql)
+        return True, sql
+    except Exception as e:
+        return False, str(e)
+
+def add_column(conn, table, col, ctype):
+    cur = conn.cursor()
+    sql = f'ALTER TABLE "{table}" ADD COLUMN "{col}" {ctype}'
+    cur.execute(sql)
+    return sql
+
+def copy_column(conn, table, src, dst):
+    cur = conn.cursor()
+    sql = f'UPDATE "{table}" SET "{dst}" = "{src}" WHERE "{dst}" IS NULL OR "{dst}" = \'\''
+    cur.execute(sql)
+    return sql
+
+def main():
+    safe_print("Starting smart updater (validated names)")
+    env = {"cwd": os.getcwd(), "python": sys.executable, "pyver": sys.version}
+    if not os.path.exists(DB_PATH):
+        safe_print("DB not found:", DB_PATH); sys.exit(2)
+    hints = load_hints()
+    attempted_ops = []
+    skipped_names = []
+    try:
+        conn = sqlite3.connect(DB_PATH, timeout=30)
+    except Exception as e:
+        tb = traceback.format_exc()
+        fn = write_report("migration_report_failed", env, attempted_ops, tb_text=tb, success=False)
+        safe_print("Failed to open DB; wrote", fn)
+        sys.exit(3)
+    try:
+        schema = get_db_schema(conn)
+        plan = []
+        for table, data in (hints or {}).items():
+            expected = data.get("expected_columns", [])
+            if table not in schema:
+                safe_print(f"Table '{table}' not in DB; skipping.")
+                continue
+            existing = schema[table]
+            for col in expected:
+                # VALIDATE name
+                if not IDENT_RE.match(col):
+                    skipped_names.append(f"{table}.{col}")
+                    continue
+                if col in existing:
+                    continue
+                candidate = None
+                for e in existing:
+                    if e.lower() == col.lower():
+                        candidate = e; break
+                if not candidate:
+                    matches = get_close_matches(col, existing, n=1, cutoff=0.78)
+                    if matches:
+                        candidate = matches[0]
+                plan.append((table, col, candidate))
+        if not plan and not skipped_names:
+            safe_print("No changes planned.")
+            sys.exit(0)
+        bak = backup_db(DB_PATH)
+        safe_print("Backup created at", bak)
+        ops = []
+        cur = conn.cursor()
+        cur.execute("BEGIN")
+        for table, expected_col, candidate in plan:
+            if candidate:
+                ops.append(f"Candidate match for {table}.{expected_col} -> {candidate}")
+                ok, info = attempt_rename(conn, table, candidate, expected_col)
+                if ok:
+                    ops.append(f"RENAME {table}.{candidate} -> {expected_col}")
+                else:
+                    ctype = guess_type(expected_col)
+                    ops.append(add_column(conn, table, expected_col, ctype))
+                    try:
+                        ops.append(copy_column(conn, table, candidate, expected_col))
+                    except Exception as e:
+                        ops.append(f"COPY failed: {e}")
+            else:
+                ctype = guess_type(expected_col)
+                ops.append(add_column(conn, table, expected_col, ctype))
+        conn.commit()
+        fn = write_report("migration_report", env, ops, tb_text=None, success=True, skipped=skipped_names)
+        safe_print("Migration SUCCESS. Report:", fn)
+        return 0
+    except Exception as e:
+        conn.rollback()
+        tb = traceback.format_exc()
+        fn = write_report("migration_report_failed", env, attempted_ops + (ops if 'ops' in locals() else []), tb_text=tb, success=False, skipped=skipped_names)
+        safe_print("Migration FAILED. Report:", fn)
+        try:
+            shutil.copy2(bak, DB_PATH)
+            safe_print("Restored backup from", bak)
+        except Exception as rexc:
+            safe_print("Failed to restore backup:", rexc)
+        return 4
+    finally:
+        try:
+            conn.close()
+        except Exception:
+            pass
+
+if __name__ == "__main__":
+    rc = main()
+    sys.exit(rc)
+
*** End Patch
*** Begin Patch
*** Add File: scripts/compat_yaml.py
+#!/usr/bin/env python3
+"""
+Compat loader for simple YAML-like schema hints without external dependency.
+If PyYAML is present, use it; otherwise parse the simple format produced by analyzer.
+Exposes: load_hints(path) -> dict
+"""
+import os
+
+def load_hints(path):
+    try:
+        import yaml
+        with open(path, "r", encoding="utf-8") as f:
+            return yaml.safe_load(f) or {}
+    except Exception:
+        pass
+    if not os.path.exists(path):
+        return {}
+    hints = {}
+    cur = None
+    try:
+        with open(path, "r", encoding="utf-8") as f:
+            for line in f:
+                if not line.strip() or line.strip().startswith("#"):
+                    continue
+                if line[0] != " ":
+                    cur = line.split(":", 1)[0].strip()
+                    hints[cur] = {"expected_columns": []}
+                else:
+                    s = line.strip()
+                    if s.startswith("- "):
+                        hints[cur]["expected_columns"].append(s[2:].strip())
+    except Exception:
+        return {}
+    return hints
+
*** End Patch
*** Begin Patch
*** Add File: db/schema_hints.yaml
+# schema_hints.yaml (generated placeholder)
+# Edit this file to correct or add expected columns before running the updater.
+#
+# Format:
+# table_name:
+#   expected_columns:
+#     - col1
+#     - col2
+#
+# Optional: add manual mappings/aliases by editing the analyzer output to the correct names.
+
+event_caisses:
+  expected_columns:
+    - nom
+    - solde_initial
+    - responsable
+
+buvette_articles:
+  expected_columns:
+    - name
+    - categorie
+    - unite
+    - contenance
+    - purchase_price
+    - commentaire
+
*** End Patch
*** Begin Patch
*** Update File: modules/buvette.py
@@
-import logging
+import logging
 logger = logging.getLogger(__name__)
 
-def _row_to_dict(cur, r):
-    if isinstance(r, dict):
-        return r
-    try:
-        if hasattr(r, "keys"):
-            return {k: r[k] for k in r.keys()}
-    except Exception:
-        pass
-    try:
-        cols = [d[0] for d in cur.description] if cur.description else []
-        if isinstance(r, (list, tuple)) and cols:
-            return {cols[i]: r[i] for i in range(min(len(cols), len(r)))}
-    except Exception:
-        pass
-    try:
-        return dict(r)
-    except Exception:
-        return {}
+def _row_to_dict(cur, r):
+    if isinstance(r, dict):
+        return r
+    try:
+        if hasattr(r, "keys"):
+            return {k: r[k] for k in r.keys()}
+    except Exception:
+        pass
+    try:
+        cols = [d[0] for d in cur.description] if cur.description else []
+        if isinstance(r, (list, tuple)) and cols:
+            return {cols[i]: r[i] for i in range(min(len(cols), len(r)))}
+    except Exception:
+        pass
+    try:
+        return dict(r)
+    except Exception:
+        return {}
 
 def refresh_articles(self):
     """Rafraîchit la treeview des articles en utilisant un accès sûr aux colonnes."""
     try:
-        for item in self.articles_tree.get_children():
-            self.articles_tree.delete(item)
-
-        cur = self.conn.cursor()
-        cur.execute("SELECT * FROM buvette_articles ORDER BY name")
-        rows = cur.fetchall()
-
-        for a in rows:
-            row = _row_to_dict(cur, a)
-            name = row.get("name", "")
-            categorie = row.get("categorie", "")
-            unite = row.get("unite", "")
-            contenance = row.get("contenance", "")
-            purchase_price = row.get("purchase_price", None)
-            if purchase_price in (None, ""):
-                purchase_price = row.get("prix_achat", "")
-            purchase_price_display = "" if purchase_price in (None, "") else str(purchase_price)
-            commentaire = row.get("commentaire", "")
-
-            values = (name, categorie, unite, contenance if contenance is not None else "", purchase_price_display, commentaire)
-            self.articles_tree.insert("", "end", values=values)
+        for item in self.articles_tree.get_children():
+            self.articles_tree.delete(item)
+
+        cur = self.conn.cursor()
+        cur.execute("SELECT * FROM buvette_articles ORDER BY name")
+        rows = cur.fetchall()
+
+        for a in rows:
+            row = _row_to_dict(cur, a)
+            name = row.get("name", "")
+            categorie = row.get("categorie", "")
+            unite = row.get("unite", "")
+            contenance = row.get("contenance", "")
+            purchase_price = row.get("purchase_price", None)
+            if purchase_price in (None, ""):
+                purchase_price = row.get("prix_achat", "")
+            purchase_price_display = "" if purchase_price in (None, "") else str(purchase_price)
+            commentaire = row.get("commentaire", "")
+
+            values = (name, categorie, unite, contenance if contenance is not None else "", purchase_price_display, commentaire)
+            self.articles_tree.insert("", "end", values=values)
     except Exception as e:
         logger.exception("Erreur lors du raffraichissement des articles")
         try:
             from tkinter import messagebox
             messagebox.showerror("Erreur", "Impossible d'afficher les articles : " + str(e))
         except Exception:
             pass
*** End Patch
*** Begin Patch
*** Add File: modules/inventory_lines_dialog.py
+#!/usr/bin/env python3
+"""
+Robust loader for inventory lines: convert sqlite results to dicts using cursor.description
+so code can use row.get(...) safely.
+Replace existing load_inventory_lines implementation with this.
+"""
+import logging
+logger = logging.getLogger(__name__)
+
+def _rows_to_dicts(cur, rows):
+    """
+    Convert fetched rows to list of dicts.
+    Handles sqlite3.Row (mapping), tuples/lists (uses cur.description), and dicts.
+    """
+    cols = []
+    try:
+        cols = [d[0] for d in cur.description] if cur.description else []
+    except Exception:
+        cols = []
+    out = []
+    for r in rows:
+        try:
+            if isinstance(r, dict):
+                out.append(r)
+            elif hasattr(r, "keys"):
+                # sqlite3.Row mapping-like
+                try:
+                    out.append({k: r[k] for k in r.keys()})
+                except Exception:
+                    if cols and isinstance(r, (list, tuple)):
+                        out.append({cols[i]: r[i] for i in range(min(len(cols), len(r)))})
+                    else:
+                        out.append(dict(r))
+            elif isinstance(r, (list, tuple)):
+                if cols:
+                    out.append({cols[i]: r[i] for i in range(min(len(cols), len(r)))})
+                else:
+                    out.append({str(i): r[i] for i in range(len(r))})
+            else:
+                out.append({})
+        except Exception:
+            try:
+                out.append(dict(r))
+            except Exception:
+                out.append({})
+    return out
+
+def load_inventory_lines(self, inventaire_id):
+    """
+    Charge et affiche les lignes liées à un inventaire.
+    Utilise _rows_to_dicts pour garantir des dicts et pouvoir faire row.get(...)
+    """
+    try:
+        cur = self.conn.cursor()
+        cur.execute(
+            "SELECT id, stock_id, quantite_constatee, ecart FROM inventaire_lignes WHERE inventaire_id = ?",
+            (inventaire_id,)
+        )
+        rows = cur.fetchall()
+        rows = _rows_to_dicts(cur, rows)
+
+        # vider la treeview (adapter au nom réel de la treeview si nécessaire)
+        for iid in self.lines_tree.get_children():
+            self.lines_tree.delete(iid)
+
+        for row in rows:
+            stock_id = row.get("stock_id", "")
+            qty = row.get("quantite_constatee", 0)
+            ecart = row.get("ecart", 0)
+            line_id = row.get("id", None)
+            self.lines_tree.insert("", "end", iid=str(line_id) if line_id is not None else None, values=(stock_id, qty, ecart))
+    except Exception as e:
+        logger.exception("Error loading inventory data")
+        try:
+            from tkinter import messagebox
+            messagebox.showerror("Erreur", "Erreur lors du chargement de l'inventaire: " + str(e))
+        except Exception:
+            pass
+
*** End Patch
*** Begin Patch
*** Add File: ui/inventory_dialog.py
+#!/usr/bin/env python3
+"""
+DetailedInventoryDialog : TopLevel dialog to create or edit an inventory and its lines.
+Usage:
+    dlg = DetailedInventoryDialog(parent, conn, inv_id=None)  # create
+    parent.wait_window(dlg.top)
+    if dlg.saved: # True if saved
+        ... refresh ...
+"""
+import tkinter as tk
+from tkinter import ttk, messagebox, simpledialog
+import datetime
+
+class DetailedInventoryDialog:
+    def __init__(self, parent, conn, inv_id=None):
+        self.parent = parent
+        self.conn = conn
+        self.inv_id = inv_id
+        self.saved = False
+        self.top = tk.Toplevel(parent)
+        self.top.transient(parent)
+        self.top.grab_set()
+        self.top.title("Nouvel inventaire détaillé" if inv_id is None else "Modifier l'inventaire")
+        self._build_ui()
+        if inv_id is not None:
+            self._load_inventory()
+
+    def _build_ui(self):
+        frm = ttk.Frame(self.top, padding=10)
+        frm.pack(fill="both", expand=True)
+        ttk.Label(frm, text="Date").grid(row=0, column=0, sticky="w")
+        self.date_var = tk.StringVar(value=datetime.date.today().isoformat())
+        ttk.Entry(frm, textvariable=self.date_var).grid(row=0, column=1, sticky="ew")
+        ttk.Label(frm, text="Type inventaire").grid(row=1, column=0, sticky="w")
+        self.type_var = tk.StringVar()
+        ttk.Combobox(frm, textvariable=self.type_var, values=["avant", "après", "hors_evenement"]).grid(row=1, column=1, sticky="ew")
+        ttk.Label(frm, text="Commentaire").grid(row=2, column=0, sticky="w")
+        self.comment_var = tk.StringVar()
+        ttk.Entry(frm, textvariable=self.comment_var).grid(row=2, column=1, sticky="ew")
+        # lines management minimal UI: a Treeview + Add/Del buttons
+        self.lines

